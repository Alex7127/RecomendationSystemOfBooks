{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <center> Разбор кейса ML-инженера"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf52Pxm2hiom"
      },
      "source": [
        "## Обучим и протестируем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEgni61ptDR7",
        "outputId": "4d9d62cf-6edf-4003-895e-3c833a2b5518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lightfm\n",
            "  Using cached lightfm-1.17.tar.gz (316 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: numpy in c:\\users\\alex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from lightfm) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\alex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from lightfm) (1.11.3)\n",
            "Requirement already satisfied: requests in c:\\users\\alex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from lightfm) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\alex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from lightfm) (1.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->lightfm) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->lightfm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->lightfm) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->lightfm) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\alex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->lightfm) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->lightfm) (3.2.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py): started\n",
            "  Building wheel for lightfm (setup.py): finished with status 'error'\n",
            "  Running setup.py clean for lightfm\n",
            "Failed to build lightfm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × python setup.py bdist_wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [38 lines of output]\n",
            "      Compiling without OpenMP support.\n",
            "      C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\setuptools\\dist.py:476: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
            "      !!\n",
            "      \n",
            "              ********************************************************************************\n",
            "              Usage of dash-separated 'description-file' will not be supported in future\n",
            "              versions. Please use the underscore name 'description_file' instead.\n",
            "      \n",
            "              By 2024-Sep-26, you need to update your project and remove deprecated calls\n",
            "              or your builds will no longer be supported.\n",
            "      \n",
            "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "              ********************************************************************************\n",
            "      \n",
            "      !!\n",
            "        opt = self.warn_dash_deprecation(opt, section)\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\n",
            "      creating build\\lib.win-amd64-cpython-39\n",
            "      creating build\\lib.win-amd64-cpython-39\\lightfm\n",
            "      copying lightfm\\cross_validation.py -> build\\lib.win-amd64-cpython-39\\lightfm\n",
            "      copying lightfm\\data.py -> build\\lib.win-amd64-cpython-39\\lightfm\n",
            "      copying lightfm\\evaluation.py -> build\\lib.win-amd64-cpython-39\\lightfm\n",
            "      copying lightfm\\lightfm.py -> build\\lib.win-amd64-cpython-39\\lightfm\n",
            "      copying lightfm\\_lightfm_fast.py -> build\\lib.win-amd64-cpython-39\\lightfm\n",
            "      copying lightfm\\__init__.py -> build\\lib.win-amd64-cpython-39\\lightfm\n",
            "      creating build\\lib.win-amd64-cpython-39\\lightfm\\datasets\n",
            "      copying lightfm\\datasets\\movielens.py -> build\\lib.win-amd64-cpython-39\\lightfm\\datasets\n",
            "      copying lightfm\\datasets\\stackexchange.py -> build\\lib.win-amd64-cpython-39\\lightfm\\datasets\n",
            "      copying lightfm\\datasets\\_common.py -> build\\lib.win-amd64-cpython-39\\lightfm\\datasets\n",
            "      copying lightfm\\datasets\\__init__.py -> build\\lib.win-amd64-cpython-39\\lightfm\\datasets\n",
            "      copying lightfm\\_lightfm_fast_no_openmp.c -> build\\lib.win-amd64-cpython-39\\lightfm\n",
            "      copying lightfm\\_lightfm_fast_openmp.c -> build\\lib.win-amd64-cpython-39\\lightfm\n",
            "      running build_ext\n",
            "      building 'lightfm._lightfm_fast_no_openmp' extension\n",
            "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for lightfm\n",
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × python setup.py clean did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [18 lines of output]\n",
            "      Compiling without OpenMP support.\n",
            "      C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\setuptools\\dist.py:476: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
            "      !!\n",
            "      \n",
            "              ********************************************************************************\n",
            "              Usage of dash-separated 'description-file' will not be supported in future\n",
            "              versions. Please use the underscore name 'description_file' instead.\n",
            "      \n",
            "              By 2024-Sep-26, you need to update your project and remove deprecated calls\n",
            "              or your builds will no longer be supported.\n",
            "      \n",
            "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "              ********************************************************************************\n",
            "      \n",
            "      !!\n",
            "        opt = self.warn_dash_deprecation(opt, section)\n",
            "      running clean\n",
            "      error: [WinError 2] РќРµ СѓРґР°РµС‚СЃСЏ РЅР°Р№С‚Рё СѓРєР°Р·Р°РЅРЅС‹Р№ С„Р°Р№Р»\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed cleaning build dir for lightfm\n",
            "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (lightfm)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightfm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O3C_SMz6hiot"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lightfm'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightfm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightFM\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightfm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightfm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_at_k, recall_at_k\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightfm'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sparse\n",
        "from lightfm import LightFM\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "qfCOflZnhiou",
        "outputId": "aa55bacd-ccab-45c0-e483-ef59d2698d94"
      },
      "outputs": [],
      "source": [
        "ratings = pd.read_csv('data/ratings.csv')\n",
        "books = pd.read_csv('data/books.csv')\n",
        "tags = pd.read_csv('data/tags.csv')\n",
        "book_tags = pd.read_csv('data/book_tags.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1TBykVuhiov"
      },
      "outputs": [],
      "source": [
        "books.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVIwztA5hiov"
      },
      "outputs": [],
      "source": [
        "mapper = dict(zip(books.goodreads_book_id,books.book_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxVDaPkKhiow"
      },
      "outputs": [],
      "source": [
        "tags = pd.read_csv('data/tags_cleaned.csv')\n",
        "book_tags = book_tags[book_tags.tag_id.isin(tags.tag_id)]\n",
        "book_tags['id'] = book_tags.goodreads_book_id.apply(lambda x: mapper[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd_WvCLDhiow"
      },
      "outputs": [],
      "source": [
        "book_tags.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3piw5iXUhiox"
      },
      "outputs": [],
      "source": [
        "ratings_coo = sparse.coo_matrix((ratings.rating,(ratings.user_id, ratings.book_id)))\n",
        "feature_ratings  = sparse.coo_matrix(([1]*len(book_tags), (book_tags.id, book_tags.tag_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp7ydLG-hiox"
      },
      "source": [
        "Объявим вспомогательные константы для обучения модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3bS12rOhioy"
      },
      "outputs": [],
      "source": [
        "#число потоков нашего процессора. Ставим 1, так как lightfm на macos ставится без OpenMP\n",
        "NUM_THREADS = 1\n",
        "\n",
        "#число параметров вектора \n",
        "NUM_COMPONENTS = 60\n",
        "\n",
        "#число эпох обучения\n",
        "NUM_EPOCHS = 10 \n",
        "\n",
        "#зерно датчика случайных чисел\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-1_C-UZhioy"
      },
      "source": [
        "На этапе создания модели мы используем библиотеку LightFM, чтобы сделать матричное разложение (ALS) наших рейтингов книг и получить два набора векторов. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGxL87INhioz"
      },
      "outputs": [],
      "source": [
        "#Разбиваем наш датасет на обучающую и тестовую выборки\n",
        "train, test = random_train_test_split(ratings_coo, test_percentage=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "#Создаём модель\n",
        "model = LightFM(\n",
        "    learning_rate=0.05, #темп (скорость) обучения\n",
        "    loss='warp', #loss-функция\n",
        "    no_components=NUM_COMPONENTS,#размерность вектора признаков\n",
        "    random_state=RANDON_STATE #генератор случайных чисел\n",
        ")\n",
        "\n",
        "#Обучаем модель\n",
        "model = model.fit(\n",
        "    train, #обучающая выборка\n",
        "    epochs=NUM_EPOCHS, #количество эпох обучения\n",
        "    num_threads=NUM_THREADS, #количество потоков процессора\n",
        "    item_features=feature_ratings #признаки товаров (рейтинги книг)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMupb7Schio0"
      },
      "source": [
        "Протестируем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U1waVUshio0"
      },
      "outputs": [],
      "source": [
        "#Тестируем нашу модель\n",
        "precision_score = precision_at_k(\n",
        "    model, #модель\n",
        "    test, #тестовая выборка\n",
        "    num_threads=NUM_THREADS, #количество потоков процессора\n",
        "    k=10, #количество предложений\n",
        "    item_features=feature_ratings #признаки товаров\n",
        ").mean() #усредняем результаты\n",
        " \n",
        "recall_score = recall_at_k(\n",
        "    model, #модель\n",
        "    test, #тестовая выборка\n",
        "    num_threads=NUM_THREADS, #количество потоков процессора\n",
        "    k=10, #количество предложений\n",
        "    item_features=feature_ratings #признаки товаров\n",
        ").mean() #усредняем результаты\n",
        "\n",
        "print(recall_score, precision_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZUskAXXhio1"
      },
      "source": [
        "Сохраним модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_uaCAe6hio1"
      },
      "outputs": [],
      "source": [
        "with open('model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30o9Rtgyhio2"
      },
      "source": [
        "## Добавим эмбеддинги к модели и посмотрим, что получилось"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqsUKn57hio2"
      },
      "outputs": [],
      "source": [
        "with open('model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQyl1ymbhio2"
      },
      "outputs": [],
      "source": [
        "# Достаём эбмеддинги\n",
        "item_biases, item_embeddings = model.get_item_representations(features=feature_ratings)\n",
        "\n",
        "print(item_biases.shape, item_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install nmslib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi1DHdBKhio3"
      },
      "outputs": [],
      "source": [
        "import nmslib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NscQUR47hio3"
      },
      "outputs": [],
      "source": [
        "#Инициализируем наш граф для поиска\n",
        "nms_idx = nmslib.init(method='hnsw', space='cosinesimil')\n",
        " \n",
        "#Начинаем добавлять наши книги в граф\n",
        "nms_idx.addDataPointBatch(item_embeddings)\n",
        "nms_idx.createIndex(print_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCtnO4s9hio3"
      },
      "outputs": [],
      "source": [
        "#Вспомогательная функция для поиска по графу\n",
        "def nearest_books_nms(book_id, index, n=10):\n",
        "    nn = index.knnQuery(item_embeddings[book_id], k=n)\n",
        "    return nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PMM_uHfhio4"
      },
      "source": [
        "Найдем id книги 1984"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da3eHj7chio5"
      },
      "outputs": [],
      "source": [
        "#Отфильтруем только те, где в названии встречается подстрока \"1984\"\n",
        "books[books['title'].apply(lambda x: x.lower().find('1984')) >= 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hxEWTJghio5"
      },
      "source": [
        "Теперь найдем все похожие книги и посмотрим на них"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Вызываем функцию для поиска ближайших соседей\n",
        "print(nearest_books_nms(846, nms_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaVVOV9Whio6"
      },
      "outputs": [],
      "source": [
        "#Выделяем идентификаторы рекомендованных книг\n",
        "nbm = nearest_books_nms(846, nms_idx)[0]\n",
        "nbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTred3b8hio6"
      },
      "outputs": [],
      "source": [
        "#Посмотрим на авторов и названия рекомендованных книг\n",
        "books[books.book_id.isin(nbm)][['authors', 'title']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV45_3xhhio7"
      },
      "source": [
        "Сохраним эмбеддинги"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUk-Xx4Zhio7"
      },
      "outputs": [],
      "source": [
        "with open('item_embeddings.pkl', 'wb') as file:\n",
        "    pickle.dump(item_embeddings, file, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.15 ('rec_sys')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "4e4104bd57aa2b23b5ece499e6a495477546c5bc7859abce1e85f57e6cf8bee2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
